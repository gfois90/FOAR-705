library(tm) #text mining
library(wordcloud)# visual
library(RWeka) #classification and eval
library(SnowballC)#word stemming
library(caret)#partitioning
library(rminer)#classification
library(kernlab)#support vector machine classifier
library(rpart)#classification, regression

#import dataset

setwd("C://Users//Grant//Desktop//")
trainsent = read.csv ("Trainsent.csv", header = T, stringsAsFactors = FALSE)
str(trainsent)
trainsent$class <-factor(Trainsent$class)

#summarize the two variables
summary(trainsent)
prop.table(table(trainsent$class))
nrow(trainsent)

#prepare train and test
set.seed(100)
inTrain <- createDataPartition(y=trainsent$class, p=0.50, list=FALSE)
train_m <- trainsent[inTrain,]
testdata <- trainsent[-inTrain,]

inTest <- createDataPartition(y=testdata$class, p=0.50, list = FALSE)
test1_m <- testdata[inTest,]
test2_m <- testdata[-inTest,]

#check parition results

nrow(train_m)
summary(train_m)
nrow(test1_m)
summary(test1_m)
nrow(test2_m)
summary(test2_m)
prop.table(table(train_m$class))
prop.table(table(test1_m$class))
prop.table(table(test2_m$class))

#TOKENIZATION

train_corpus_m <- Corpus(VectorSource(train_m$text))
length(train_corpus_m)

#cleaning the dataset

train_m$text[1] 
Step1 <- tm_map(train_corpus_m, tolower)
Step1[1]

#remove numerics
Step2 <- tm_map(Step1, removeNumbers)
Step2[1]

#further cleaning

Step3 <- tm_map(Step2, removeWords, stopwords("english"))
Step3 <- tm_map(Step2, removeWords, stopwords())
Step3[[1]]

Step4 <- tm_map(Step3, removePunctuation)
Step4[[1]]

Step5 <- tm_map(Step4, stripWhitespace)
Step5[[1]]

Step6 <- tm_map(Step5, stemDocument, language = "english")
Step6[[1]]


#Transform the corpus to DTM 

train_dtm_m = DocumentTermMatrix(Step6)
dim(train_dtm_m)
#remove sparse terms
train_rmspa_m = removeSparseTerms(train_dtm_m, 0.80)
dim(train_rmspa_m)

#show avg. freq. top 20 words
mean_train = sort(colMeans(as.matrix(train_rmspa_m)), decreasing=T)
mean_train[1:20]
average_top20=mean(mean_train[1:20])
average_top20

#show freq. in a bar plot
barplot(mean_train[1:20], border = NA, las = 3, xlab = "top 20 words", ylab = "Frequency", ylim = c(0,3))

#remvoe pointless words

mystopwords <- c("film", "films", "get", "one", "two", "three", "just", "movies", "movie")
train_corpus_m <- tm_map(train_corpus_m, removeWords, mystopwords)

train_dtm_m = DocumentTermMatrix(train_corpus_m, control = list(tolower = T, removeNumbers = T, removePunctuation = T, stopwords = T, stripWhitespace = T, stemming = T))
dim(train_dtm_m)

train_rmspa_m = removeSparseTerms(train_dtm_m, 0.80)
dim(train_rmspa_m)

#show avg. freq. with our classified words removed 

mean_train_m = sort(colMeans(as.matrix(train_rmspa_m)), decreasing = T)
mean_train_m[1:20]
average_top20_m = mean(mean_train_m[1:20])
average_top20_m

barplot(mean_train_m[1:20], border = NA, las = 3, xlab = "top 20 words", ylab = "Frequency", ylim = c(0,3))

#wordcloud

wordcloud(names(mean_train_m[1:30]), mean_train_m[1:30], scale = c(5,1), colors=brewer.pal(8, "Dark2"))

#SENTIMENT CLASSIFICAITON 
#GENERATE TRAINING DATASET

train_BoWfreq <- as.matrix(train_rmspa_m)
# combine the sentiment label with term frequencies of the BoW in training data 
train_data_m = data.frame(y=train_m$class, x=train_BoWfreq)
summary(train_data_m)
str(train_data_m)

train_BoW_m=findFreqTerms(train_rmspa_m)
length(train_BoW_m)

#Now to generate test1_data_n which includes test1's term freq. of words slected from the train data

test1_corpus_m <- Corpus(DataframeSource(as.matrix(test1_m$text)))
#generate test1s dtm based on bag of words decided by training data

bow_test1_m <- DocumentTermMatrix(test1_corpus_m, control = list(tolower = T, removeNumbers = T, removePunctuation = T, stopwords = T, stripWhitespace = T, stemming = T, dictionary = train_BoW_m))

str(bow_test1_m)
dim(bow_test1_m)

#transform format from dtm to matrix

test1_bowfreq_m <- as.matrix(bow_test1_m)

#combine the sentiment label with the term freq. of the bow in test 1 into a data frame

test1_data_m = data.frame(y=test1_m$class, x=test1_bowfreq_m)
str(test1_data_m)
summary(test1_data_m)


library(e1071)

bow_nb_m = naiveBayes(y ~ ., data = train_data_m)
summary(bow_nb_m)
test1pred = predict(bow_nb_m, newdata = test1_data_m)
confusionMatrix(test1pred, test1_data_m[,1], positive = "Pos", dnn = c ("Prediction", "True"))
mmetric(test1pred, test1_data_m[,1], c("ACC", "TPR", "PRECISION", "F1"))

library(kernlab)
bow_ksvm_m= ksvm(y ~ ., data = train_data_m)
test1pred = predict(bow_ksvm_m, newdata = test1_data_m)
confusionMatrix(test1pred, test1_data_m[,1], positive = "Pos", dnn = c ("Precition", "True"))
mmetric(test1pred, test1_data_m[,1], c("ACC", "TPR", "PRECISION", "F1"))


